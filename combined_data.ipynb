{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Data explanation placeholder\n",
    "\n",
    "(Talk about original two notebooks?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data\n",
    "df_movies = pd.read_csv(\"./Resources/movies_data.csv\")\n",
    "df_economics = pd.read_csv(\"./Resources/economics_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Economics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a 'Date' for a datetime index\n",
    "df_movies['Date'] = pd.to_datetime({\n",
    "    'year': df_movies['released_year'],\n",
    "    'month': df_movies['released_month'],\n",
    "    'day': df_movies['released_day']\n",
    "})\n",
    "\n",
    "# Setting `Date` as index\n",
    "df_movies.set_index('Date', inplace=True)\n",
    "\n",
    "# Ensuring index is sorted with ascending dates\n",
    "df_movies.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a `Year` and `Month` for concatenation\n",
    "df_economics['Year'] = df_economics['Date'].str.slice(0,4).astype(int)\n",
    "df_economics['Month'] = df_economics['Date'].str.slice(5,7).astype(int)\n",
    "\n",
    "# Renaming to `Year` and `Month` for concatenation\n",
    "df_movies.rename(columns={\n",
    "'released_year': 'Year',\n",
    "'released_month': 'Month'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming total records before concatenation\n",
    "print(f'Total ecomonic records: {df_economics.shape[0]}')\n",
    "print(f'Total movie records: {df_movies.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining datasets through concatenation\n",
    "df_combined = pd.merge(df_economics, df_movies, how='left', on=['Year', 'Month'])\n",
    "\n",
    "# Confirming total records after concatenation\n",
    "print(f'Total records: {df_combined.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the eventual `Target` for modelling\n",
    "df_combined['Target'] = df_combined['critical_success'] + ' ' +\\\n",
    "                        df_combined['financial_success'] + ' ' +\\\n",
    "                        df_combined['Economic Climate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of features to drop\n",
    "cols_to_drop = [\n",
    "    'Economic Climate',\n",
    "    'Year',\n",
    "    'Month',\n",
    "    'id',\n",
    "    'critical_success',\n",
    "    'financial_success',\n",
    "    'released_day'\n",
    "]\n",
    "\n",
    "# Dropping unneeded features\n",
    "df_combined.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining columns to scale and encode\n",
    "col_to_scale = [\n",
    "    'CCI Value', 'CCI Rolling Mean', 'CCI Rolling Percent Change',\n",
    "    'CPI Value', 'CPI Rolling Mean', 'CPI Rolling Percent Change',\n",
    "    'Unemployment Rate (%)', 'Unemployment Rate (%) Rolling Mean',\n",
    "    'Unemployment Rate Rolling Percent Change','vote_average', 'vote_count',\n",
    "    'revenue','runtime','budget', 'popularity', 'roi'\n",
    "]\n",
    "\n",
    "col_to_encode = [\n",
    "    'Date','CCI Rolling Percent Change Flag', 'CPI Rolling Percent Change Flag',\n",
    "    'Unemployment Rate Rolling Percent Change Flag', 'title',\n",
    "    'status', 'release_date','original_language', 'original_title',\n",
    "    'genres', 'production_companies', 'production_countries',\n",
    "    'spoken_languages', 'cast', 'director', 'writers', 'producers'\n",
    "]\n",
    "\n",
    "# Setup X and y variables\n",
    "X = df_combined.drop(columns='Target')\n",
    "y = df_combined['Target']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling and Econding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit(X_train[col_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train[col_to_scale])\n",
    "X_test_scaled = scaler.transform(X_test[col_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=scaler.get_feature_names_out())\n",
    "X_test_scaled = pd.DataFrame(X_train_scaled, columns=scaler.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_x = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "encoder_x.fit(X_train[col_to_encode].values.reshape(-1,1))\n",
    "\n",
    "encoder_y = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "encoder_y.fit(y_train.values.reshape(-1,1))\n",
    "\n",
    "# Transform each column into numpy arrays\n",
    "X_train_encoded = encoder_x.transform(X_train[col_to_encode].values.reshape(-1,1))\n",
    "X_test_encoded = encoder_x.transform(X_test[col_to_encode].values.reshape(-1,1))\n",
    "\n",
    "y_train_encoded = encoder_y.transform(y_train.values.reshape(-1,1))\n",
    "y_test_encoded = encoder_y.transform(y_test.values.reshape(-1,1))\n",
    "\n",
    "# Reorganize the numpy arrays into a DataFrame\n",
    "X_train_encoded = pd.DataFrame(X_train_encoded, columns=encoder_x.get_feature_names_out())\n",
    "X_test_encoded = pd.DataFrame(X_test_encoded, columns=encoder_x.get_feature_names_out())\n",
    "\n",
    "# Concatenate the encoded columns with the scaled columns\n",
    "X_train = pd.concat([X_train_scaled, X_train_encoded], axis=1)\n",
    "X_test = pd.concat([X_test_scaled, X_test_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Playtime!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eric's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funda's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalvin's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Odele's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peta's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vadim's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "ai_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
