{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reel Returns**\n",
    "#### *Machine Learning Insights into Movie Profitability*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Importing dependencies\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Importing dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Data explanation placeholder\n",
    "\n",
    "(Talk about original two notebooks?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data\n",
    "df_movies = pd.read_csv(\"./Resources/movies_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Economics Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While classifying economic states is a complex and nuanced issue, it is not unreasonable to draw more broad-strokes generalizations about a given timeframe based on more limited factors. To serve the purposes of our modelling, the following three factors were chosen to highlight the economic status at a given movie's release date;\n",
    "\n",
    "* Consumer Confidence Indicator (CCI)\n",
    "* Consumer Price Index (CPI)\n",
    "* Unemployment Rate\n",
    "\n",
    "These features are further discussed below, and stand as adequate datapoints to answer three respective questions;\n",
    "\n",
    "* How likely are people to be spending money?\n",
    "* How much do things cost when they do spend money?\n",
    "* How many people have jobs to earn money to spend?\n",
    "\n",
    "As detailed below, this information came as monthly measures over several decades. To create our `Economic Climate` indicator - a classification as to whether or not the economics of a given time were on the better side for consumers - we will need to calculate a rolling 12-month percent change in the mean of those monthly values in order to show if a given feature was on a positive or negative trend for the provided period.\n",
    "\n",
    "---\n",
    "\n",
    "The following datasets are courtesy of __[Kaggle](https://www.kaggle.com/)__.\n",
    "\n",
    "### __['...CCI_OECD.csv'](https://www.kaggle.com/datasets/iqbalsyahakbar/cci-oecd)__\n",
    "\n",
    "*renamed from `DP_LIVE_16112023095843236.csv`*\n",
    "\n",
    "Per the Organisation for Economic Co-operation and Development (OECD);\n",
    "\n",
    "* The CCI is an indication of developments for future households' consumption and saving based on expected financial situation, sentiment regarding the general economic situation, employment status, and capacity for savings\n",
    "* An indicator above `100` indicates an optimistic outlook and a greater likliehood to spend money over cautious saving\n",
    "* An indicator below `100` indicates a pessimistic outlook and both a higher likeliehood to save money and a lower tendency to consume\n",
    "\n",
    "### __['...US_inflation_rates.csv'](https://www.kaggle.com/datasets/pavankrishnanarne/us-inflation-dataset-1947-present)__\n",
    "\n",
    "Per the dataset description;\n",
    "\n",
    "* The CPI is a critical economic indicator for measuring the purchasing power of money over time, measuring the average change over time in the prices paid by urban consumers for goods and services\n",
    "* The CPI is the value at the end of the respective month\n",
    "\n",
    "---\n",
    "\n",
    "The following datasets are courtesy of the __[Economic Policy Instituteâ€™s (EPI) State of Working America Data Library](https://www.epi.org/data/)__.\n",
    "\n",
    "### __['...Unemployment.csv'](https://www.epi.org/data/#?subject=unemp)__\n",
    "\n",
    "Per EPI description;\n",
    "\n",
    "* Unemployment is the share of the labor force wihout a job\n",
    "* Monthly percentages calculated as a rolling 12-month average (mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data\n",
    "df_unemp = pd.read_csv(\"./Resources/EPI Data Library - Unemployment.csv\")\n",
    "df_cci = pd.read_csv(\"./Resources/CCI_OECD.csv\")\n",
    "df_inflation = pd.read_csv(\"./Resources/US_inflation_rates.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions\n",
    "\n",
    "Since each dataset will need similar preprocessing, the following functions will be used to help streamline the flow and code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal functions\n",
    "\n",
    "Applicable to all datasets\n",
    "\n",
    "#### EDA routine\n",
    "\n",
    "Labelling and displaying pertinant information about a given dataset for the purposes of expedited EDA\n",
    "\n",
    "#### Copying datasets\n",
    "\n",
    "Creating a working copy of a given dataset to preserve the original DF with unneeded features dropped\n",
    "\n",
    "#### Renaming needed features\n",
    "\n",
    "Renaming selected features for a given dataset\n",
    "\n",
    "#### Rolling mean and mean percent change\n",
    "\n",
    "Calculating the rolling 12-month mean and the rolling 12-month percent change for a given feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to display the `.describe()`, `.shape`, and `.dtypes`\n",
    "# for a given DF\n",
    "def eda_routine(df):\n",
    "    print('Describe:')\n",
    "    display(df.describe())\n",
    "    print(f'Shape: {df.shape}\\n')\n",
    "    print(f'Data types:')\n",
    "    display(df.dtypes)\n",
    "\n",
    "# Defining a function to copy a dataset with only the needed features\n",
    "def copy_df(df, features_to_keep):\n",
    "    df_copy = df[features_to_keep].copy()\n",
    "    return df_copy\n",
    "\n",
    "# Defining a function to rename needed features\n",
    "def rename_features(df, feature1, feature1new, feature2, feature2new):\n",
    "    df.rename(columns={\n",
    "        feature1: feature1new,\n",
    "        feature2: feature2new\n",
    "    }, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Defining a function to calculate the rolling 12-month means and percent changes\n",
    "# for a given feature\n",
    "def rolling_calcs(df, feature, feature_mean, feature_pct_chng):\n",
    "    df[feature_mean] = df[feature].rolling(window=12).mean()\n",
    "    df[feature_pct_chng] = df[feature_mean].pct_change(periods=12) * 100\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Situational functions\n",
    "\n",
    "Applicable to select datasets\n",
    "\n",
    "#### Datetime indexing\n",
    "\n",
    "Converting the feature containing the raw datetime information into a suitable datetime index\n",
    "\n",
    "*Cannot be used on `Unemployment` dataset*\n",
    "\n",
    "#### Removing '%'\n",
    "\n",
    "Removing the `'%'` from a given feature and converting the remaining `object` dtype to `float`\n",
    "\n",
    "*Specigically for `Unemployment` dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to set a `Date` feature as a datetime index\n",
    "def datetime_index(df, datetime_feature):\n",
    "    df[datetime_feature] = pd.to_datetime(df[datetime_feature])\n",
    "    df.set_index(datetime_feature, inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "# Defining a function to remove '%' and convert data `float`\n",
    "def convert_percentage(feature):\n",
    "    return float(feature.strip('%'))\n",
    "\n",
    "# Defining a function to apply `convert_percentage`\n",
    "def apply_percentage(df, feature):\n",
    "    df[feature] = df[feature].apply(convert_percentage)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCI\n",
    "\n",
    "#### Preprocessing of the `CCI_OECD.csv` dataset\n",
    "\n",
    "This dataset came with internaitonal records and unneeded features, so only records for US CCI will be retained. Once those records have been selected, the resulting DF will need to be prepared for concatenation with the remainined economic datasets. To do this, the `TIME` feature will be converted to datetime and set as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing `df_cci`\n",
    "df_cci.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beginning of limited EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying `eda_routine` to `df_cci`\n",
    "eda_routine(df_cci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuing EDA\n",
    "df_cci['LOCATION'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting only domestic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying domestic data from `df_cci` to `df_cci_us` and removing unneeded features\n",
    "df_cci_us = df_cci.loc[df_cci['LOCATION'] == 'USA'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying `df_cci_us` and dropping unneeded features\n",
    "df_cci_form = copy_df(df_cci_us, ['TIME', 'Value'])\n",
    "\n",
    "# Renamining retained features\n",
    "df_cci_form = rename_features(\n",
    "    df_cci_form, 'TIME', 'Date', 'Value', 'CCI Value'\n",
    ")\n",
    "\n",
    "# Converting `Date` to a datetime index\n",
    "df_cci_form = datetime_index(df_cci_form, 'Date')\n",
    "\n",
    "# Calculating rolling 12-month means and percent change in means\n",
    "df_cci_form = rolling_calcs(\n",
    "    df_cci_form, 'CCI Value', 'CCI Rolling Mean', 'CCI Rolling Percent Change'\n",
    ")\n",
    "\n",
    "# Confirming `df_cci_form` ready to concatenate\n",
    "display(df_cci_form.head())\n",
    "display(df_cci_form.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inflation\n",
    "\n",
    "#### Preprocessing of the `US_inflation_rates.csv` dataset\n",
    "\n",
    "Seeing as the dataset came with only the needed features, little will be needed to prepare the DF for concatenation with the other economic datasets. `date` will be converted to datetime and set as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing `df_inflation`\n",
    "df_inflation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beginning of limited EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying `eda_routine` to `df_inflation`\n",
    "eda_routine(df_inflation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying `df_inflation` and dropping unneeded features\n",
    "df_inflation_form = copy_df(df_inflation, ['date', 'value'])\n",
    "\n",
    "# Renamining retained features\n",
    "df_inflation_form = rename_features(\n",
    "    df_inflation_form, 'date', 'Date', 'value', 'CPI Value'\n",
    ")\n",
    "\n",
    "# Converting `Date` to a datetime index\n",
    "df_inflation_form = datetime_index(df_inflation_form, 'Date')\n",
    "\n",
    "# Calculating rolling 12-month means and percent change in means\n",
    "df_inflation_form = rolling_calcs(\n",
    "    df_inflation_form,\n",
    "    'CPI Value',\n",
    "    'CPI Rolling Mean',\n",
    "    'CPI Rolling Percent Change'\n",
    ")\n",
    "\n",
    "# Confirming `df_inflation_form` ready to concatenate\n",
    "display(df_inflation_form.head())\n",
    "display(df_inflation_form.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment\n",
    "\n",
    "#### Preprocessing of the `Unemployment.csv` dataset\n",
    "\n",
    "This dataset came with unneeded features that will need to be dropped, as well as the needed features will need to be converted to `float`. Additionally, the `Date` feature will need to be converted to datetime and set to the index in preparation for concatenation with the other economic datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing `df_unemp`\n",
    "df_unemp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beginning of limited EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying `eda_routine` to `df_unemp`\n",
    "eda_routine(df_unemp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying defined functions (first pass)\n",
    "\n",
    "*Given the nature of the* `Date` *feature in this dataset, the datetime indexing will need to be handled outside of the defined functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying `df_unemp` and dropping unneeded features\n",
    "df_unemp_form = copy_df(df_unemp, ['Date', 'All'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming needed feature\n",
    "\n",
    "*This dataset only needed one feature,* `All`*, to be renmaned, therefore the* `rename_features` *defined function is not applicable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the reatined feature\n",
    "df_unemp_form.rename(columns={'All': 'Unemployment Rate (%)'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datetime indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `Date` feature will need to be engineered into a workable datetime feature\n",
    "\n",
    "# Creating a dictionary of Months\n",
    "month_map = {\n",
    "    'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
    "    'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
    "}\n",
    "\n",
    "# Mapping integer month values to `Date Month`\n",
    "df_unemp_form['Date Month'] = df_unemp_form['Date'].str.slice(0,3).map(month_map)\n",
    "\n",
    "# Slicing `Date Year`\n",
    "df_unemp_form['Date Year'] = df_unemp_form['Date'].str.slice(4,8)\n",
    "\n",
    "# Converting `Date` to datetime using `Date Month` and `Date Year`\n",
    "df_unemp_form['Date'] = pd.to_datetime({\n",
    "    'year': df_unemp_form['Date Year'],\n",
    "    'month': df_unemp_form['Date Month'],\n",
    "    'day': 1\n",
    "})\n",
    "\n",
    "# Dropping engineered features `Date Month` and `Date Year`\n",
    "df_unemp_form.drop(columns=['Date Month', 'Date Year'], inplace=True)\n",
    "\n",
    "# Setting `Date` as index\n",
    "df_unemp_form.set_index('Date', inplace=True)\n",
    "\n",
    "# Ensuring index is sorted with ascending dates\n",
    "df_unemp_form.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying defined functions (second pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying `apply_percentage` to `Unemployment Rate (%)`\n",
    "df_unemp_form = apply_percentage(df_unemp_form, 'Unemployment Rate (%)')\n",
    "\n",
    "# Calculating rolling 12-month means and percent change in means\n",
    "df_unemp_form = rolling_calcs(\n",
    "    df_unemp_form,\n",
    "    'Unemployment Rate (%)',\n",
    "    'Unemployment Rate (%) Rolling Mean',\n",
    "    'Unemployment Rate Rolling Percent Change',\n",
    ")\n",
    "\n",
    "# Confirming `df_unemp_form` ready to concatenate\n",
    "display(df_unemp_form.head())\n",
    "display(df_unemp_form.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Economics\n",
    "\n",
    "#### Preprocessing of the `df_economics` DF\n",
    "\n",
    "With all datasets set to a monthly datetime index, the relevent features of all can be combined into one DF, and any NaN records can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconfirming total records and features for datasets\n",
    "df_cci_form.shape, df_inflation_form.shape, df_unemp_form.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the economic datasets into `df_economics`\n",
    "df_economics = pd.concat(\n",
    "    [\n",
    "        df_cci_form,\n",
    "        df_inflation_form,\n",
    "        df_unemp_form\n",
    "    ], axis=1, join='outer'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling `NaN` rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming total records and features\n",
    "df_economics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking total `NaN` records\n",
    "df_economics.isna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping `NaN` records\n",
    "df_economics.dropna(inplace=True)\n",
    "\n",
    "# Confirming remaining records\n",
    "df_economics.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming final economic DF\n",
    "display(df_economics.head())\n",
    "display(df_economics.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering\n",
    "\n",
    "#### Engineering the economic target value\n",
    "\n",
    "As stated, the goal is to create an indicator for `Economic Climate` based on broad-strokes observations of our datasets. Having calculated the rolling 12-month percent change for each feature - based off the rolling 12-month mean - we can look for a positive or negative change in values and flag the movement accordingly. From there, we can make the following simple statements;\n",
    "\n",
    "* For **CCI**, a positive change is \"good\", as it indicates an increase in the likelihood of consumers to spend money\n",
    "* For **CPI**, a negative change is \"good\", as it indicates a decrease in the costs for goods and services\n",
    "* For **Unemployment Rate**, a negative change is \"good\", as it indicates an incrase in the population active in the workforce\n",
    "\n",
    "Therefore, we can interpret movement contrary to those changes as \"bad\". With this simplified view of the features, we can draw a classification as follows;\n",
    "\n",
    "* If **at least two (2) features** have a \"good\" value, we can set `Economic Climate` to `Comfortable to Good`\n",
    "* If **at least two (2) features** have a \"bad\" value, we can set `Economic Climate` to `Lean to Bad`\n",
    "\n",
    "In this way, we can gague whether the ecnomic state at a given rlease date supports or disproves our hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continued EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuing EDA\n",
    "df_economics.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifying `Economic Climate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of features\n",
    "features_to_flag = [\n",
    "    'CCI Rolling Percent Change',\n",
    "    'CPI Rolling Percent Change',\n",
    "    'Unemployment Rate Rolling Percent Change'\n",
    "]\n",
    "\n",
    "# Looping through `features_to_flag` to assign `positive` and `negative` indicators\n",
    "for col in df_economics[features_to_flag].columns:\n",
    "    new_col = str(col) + ' Flag'\n",
    "    df_economics.loc[df_economics[col] > 0, new_col] = 'positive'\n",
    "    df_economics.loc[df_economics[col] <= 0, new_col] = 'negative'\n",
    "\n",
    "# Creating a of list flagged features\n",
    "flag_cols = [\n",
    "    'CCI Rolling Percent Change Flag',\n",
    "    'CPI Rolling Percent Change Flag',\n",
    "    'Unemployment Rate Rolling Percent Change Flag'\n",
    "]\n",
    "\n",
    "# Confirming indicators applied\n",
    "df_economics[flag_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of conditions and classifications\n",
    "conditions = [\n",
    "    ((df_economics[flag_cols[0]] == 'positive') &   # CCI = 'positive'/good\n",
    "    (df_economics[flag_cols[1]] == 'positive') &    # CPI = 'positive'/bad\n",
    "    (df_economics[flag_cols[2]] == 'positive'),     # Unemplyment = 'positive'/bad\n",
    "    'Lean to Bad'),\n",
    "    ((df_economics[flag_cols[0]] == 'positive') &   # CCI = 'positive'/good\n",
    "    (df_economics[flag_cols[1]] == 'positive') &    # CPI = 'positive'/bad\n",
    "    (df_economics[flag_cols[2]] == 'negative'),     # Unemplyment = 'negative'/good\n",
    "    'Comfortable to Good'),\n",
    "    ((df_economics[flag_cols[0]] == 'positive') &   # CCI = 'positive'/good\n",
    "    (df_economics[flag_cols[1]] == 'negative') &    # CPI = 'negative'/good\n",
    "    (df_economics[flag_cols[2]] == 'positive'),     # Unemplyment = 'positive'/bad\n",
    "    'Comfortable to Good'),\n",
    "    ((df_economics[flag_cols[0]] == 'negative') &   # CCI = 'negative'/bad\n",
    "    (df_economics[flag_cols[1]] == 'positive') &    # CPI = 'positive'/bad\n",
    "    (df_economics[flag_cols[2]] == 'positive'),     # Unemplyment = 'positive'/bad\n",
    "    'Lean to Bad'),\n",
    "    ((df_economics[flag_cols[0]] == 'negative') &   # CCI = 'negative'/bad\n",
    "    (df_economics[flag_cols[1]] == 'negative') &    # CPI = 'negative'/good\n",
    "    (df_economics[flag_cols[2]] == 'positive'),     # Unemplyment = 'positive'/bad\n",
    "    'Lean to Bad'),\n",
    "    ((df_economics[flag_cols[0]] == 'negative') &   # CCI = 'negative'/bad\n",
    "    (df_economics[flag_cols[1]] == 'positive') &    # CPI = 'positive'/bad\n",
    "    (df_economics[flag_cols[2]] == 'negative'),     # Unemplyment = 'negative'/good\n",
    "    'Lean to Bad'),\n",
    "    ((df_economics[flag_cols[0]] == 'positive') &   # CCI = 'positive'/good\n",
    "    (df_economics[flag_cols[1]] == 'negative') &    # CPI = 'negative'/good\n",
    "    (df_economics[flag_cols[2]] == 'negative'),     # Unemplyment = 'negative'/good\n",
    "    'Comfortable to Good'),\n",
    "    ((df_economics[flag_cols[0]] == 'negative') &   # CCI = 'negative'/bad\n",
    "    (df_economics[flag_cols[1]] == 'negative') &    # CPI = 'negative'/good\n",
    "    (df_economics[flag_cols[2]] == 'negative'),     # Unemplyment = 'negative'/good\n",
    "    'Comfortable to Good')\n",
    "]\n",
    "\n",
    "# Declaring `Economic Climate` with a `PLACEHOLDER` value\n",
    "df_economics['Economic Climate'] = 'PLACEHOLDER'\n",
    "\n",
    "# Applying conditions and classifications to `Economic Climate`\n",
    "for condition, classification in conditions:\n",
    "    df_economics.loc[condition, 'Economic Climate'] = classification\n",
    "\n",
    "# Confirming classifications applied\n",
    "df_economics['Economic Climate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of features\n",
    "features_to_plot = [\n",
    "    'CCI Value',\n",
    "    'CPI Value',\n",
    "    'Unemployment Rate (%)'\n",
    "]\n",
    "\n",
    "# Creating a value of `0` to show positive and negative values\n",
    "zero_line = pd.DataFrame({\n",
    "    'Date': df_economics.index,\n",
    "    'val': [x for x in 0*df_economics[features_to_flag[2]]]\n",
    "})\n",
    "zero_line.set_index('Date', inplace=True)\n",
    "\n",
    "# Creating a value of `100` to show break point for CCI\n",
    "hundred_line = pd.DataFrame({\n",
    "    'Date': df_economics.index,\n",
    "    'val': [x for x in (0*df_economics[features_to_flag[0]])+100]\n",
    "})\n",
    "hundred_line.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing trends for `CCI Value`\n",
    "plt.plot(hundred_line, color='black', linestyle='--')\n",
    "plt.plot(df_economics[features_to_plot[0]], label='CCI', color='blue')\n",
    "plt.title('Values above 100 (visualized)\\n indicate consumers more likely to spend vs save')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing trends for `CCI Rolling Percent Change`\n",
    "plt.plot(zero_line, color='black', linestyle='--')\n",
    "plt.plot(df_economics[features_to_flag[0]], label='% Changes in CCI', color='blue')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing trends for `CPI Value`\n",
    "plt.plot(df_economics[features_to_plot[1]], label='CPI', color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing trends for `CPI Rolling Percent Change`\n",
    "plt.plot(zero_line, color='black', linestyle='--')\n",
    "plt.plot(df_economics[features_to_flag[1]], label='% Changes in CPI', color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing trends for `Unemployment Rate (%)`\n",
    "plt.plot(df_economics[features_to_plot[2]], label='Unemployment Rate (%)', color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing trends for `Unemployment Rate Rolling Percent Change`\n",
    "plt.plot(zero_line, color='black', linestyle='--')\n",
    "plt.plot(df_economics[features_to_flag[2]], label='% Changes in Unemployment Rate', color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizing total years classified in `Economic Climate`\n",
    "plt.barh(\n",
    "    y=df_economics['Economic Climate'].value_counts().index,\n",
    "    width=df_economics['Economic Climate'].value_counts()/12,\n",
    "    color=['darkblue', 'darkgreen'],\n",
    "    label=['26.42', '16.25']\n",
    ")\n",
    "plt.title(\n",
    "    'Years from 1981 to 2023 Classified as',\n",
    "    loc='left',\n",
    "    pad=15\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index to recreate `Date` for later concatenation\n",
    "df_economics.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a 'Date' for a datetime index\n",
    "df_movies['Date'] = pd.to_datetime({\n",
    "    'year': df_movies['released_year'],\n",
    "    'month': df_movies['released_month'],\n",
    "    'day': df_movies['released_day']\n",
    "})\n",
    "\n",
    "# Setting `Date` as index\n",
    "df_movies.set_index('Date', inplace=True)\n",
    "\n",
    "# Ensuring index is sorted with ascending dates\n",
    "df_movies.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a `Year` and `Month` for concatenation\n",
    "df_economics['Year'] = df_economics['Date'].dt.strftime('%Y').astype(int)\n",
    "df_economics['Month'] = df_economics['Date'].dt.strftime('%m').astype(int)\n",
    "\n",
    "# Renaming to `Year` and `Month` for concatenation\n",
    "df_movies.rename(columns={\n",
    "'released_year': 'Year',\n",
    "'released_month': 'Month'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming total records before concatenation\n",
    "print(f'Total ecomonic records: {df_economics.shape[0]}')\n",
    "print(f'Total movie records: {df_movies.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining datasets through concatenation\n",
    "df_combined = pd.merge(df_economics, df_movies, how='left', on=['Year', 'Month'])\n",
    "\n",
    "# Confirming total records after concatenation\n",
    "print(f'Total records: {df_combined.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the eventual `Target` for modelling\n",
    "df_combined['Target'] = df_combined['critical_success'] + ' ' +\\\n",
    "                        df_combined['financial_success'] + ' ' +\\\n",
    "                        df_combined['Economic Climate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of features to drop\n",
    "cols_to_drop = [\n",
    "    'Date',\n",
    "    'CCI Rolling Mean',\n",
    "    'CPI Rolling Mean',\n",
    "    'Unemployment Rate (%) Rolling Mean',\n",
    "    'Economic Climate',\n",
    "    'Year',\n",
    "    'Month',\n",
    "    'id',\n",
    "    'cast',\n",
    "    'original_language',\n",
    "    'director',\n",
    "    'writers',\n",
    "    'producers',\n",
    "    'popularity', \n",
    "    'critical_success',\n",
    "    'financial_success',\n",
    "    'release_date',\n",
    "    'released_day',\n",
    "    'production_countries',\n",
    "    'status',\n",
    "    'spoken_languages'\n",
    "]\n",
    "\n",
    "# Dropping unneeded features\n",
    "df_combined.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping `NaN` records\n",
    "df_combined.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming total records after concatenation\n",
    "print(f'Total records: {df_combined.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining columns to scale and encode\n",
    "col_to_scale = [\n",
    "    'CCI Value', 'CCI Rolling Percent Change', 'CPI Value',\n",
    "    'CPI Rolling Percent Change', 'Unemployment Rate (%)', \n",
    "    'Unemployment Rate Rolling Percent Change','vote_average', 'vote_count',\n",
    "    'revenue','runtime','budget', 'roi'\n",
    "]\n",
    "\n",
    "col_to_encode = [\n",
    "    'CCI Rolling Percent Change Flag', 'CPI Rolling Percent Change Flag',\n",
    "    'Unemployment Rate Rolling Percent Change Flag', 'title', 'original_title',\n",
    "    'genres', 'production_companies'\n",
    "]\n",
    "\n",
    "# Setup X and y variables\n",
    "X = df_combined.drop(columns='Target')\n",
    "y = df_combined['Target']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling and Econding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance for `StandardScalar()`\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting and transforming to `col_to_scale`\n",
    "X_train_scaled = scaler.fit_transform(X_train[col_to_scale])\n",
    "X_test_scaled = scaler.transform(X_test[col_to_scale])\n",
    "\n",
    "# Converting results to DF for later concatenation\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=col_to_scale)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=col_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance for `OneHotEncoder()` for `X_train[col_to_encode]`\n",
    "encoder_x = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fitting to `col_to_encode`\n",
    "encoder_x.fit(X_train[col_to_encode])\n",
    "\n",
    "# Creating an instance for `OneHotEncoder()` for `y_train`\n",
    "encoder_y = LabelEncoder()\n",
    "\n",
    "#Fitting\n",
    "encoder_y.fit(y_train.values.ravel())\n",
    "\n",
    "# Transforming `X_train[col_to_encode]` and `X_test[col_to_encode]`\n",
    "X_train_encoded = encoder_x.transform(X_train[col_to_encode])\n",
    "X_test_encoded = encoder_x.transform(X_test[col_to_encode])\n",
    "\n",
    "# Transforming `y_train` and `y_test`\n",
    "y_train_encoded = encoder_y.transform(y_train.values.ravel())\n",
    "y_test_encoded = encoder_y.transform(y_test.values.ravel())\n",
    "\n",
    "# Converting results to DF for later concatenation\n",
    "X_train_encoded = pd.DataFrame(X_train_encoded, columns=encoder_x.get_feature_names_out())\n",
    "X_test_encoded = pd.DataFrame(X_test_encoded, columns=encoder_x.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the `col_to_scale` with `col_to_encode` for `X_train` and `X_test`\n",
    "X_train = pd.concat([X_train_scaled, X_train_encoded], axis=1)\n",
    "X_test = pd.concat([X_test_scaled, X_test_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming total records after concatenation\n",
    "print(f'Total X records: {X_train.shape[0] + X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Playtime!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eric's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funda's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalvin's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a untuned KNN classifier\n",
    "untuned_model = KNeighborsClassifier()\n",
    "\n",
    "## Train the untuned model\n",
    "untuned_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Check the model's accuracy on the test set\n",
    "untuned_y_test_pred = untuned_model.predict(X_test)\n",
    "print(accuracy_score(y_test_encoded, untuned_y_test_pred))\n",
    "print(precision_score(y_test_encoded, untuned_y_test_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the PCA instance and declare the number of PCA variables to retain maximum variance\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a untuned KNN classifier\n",
    "untuned_model = KNeighborsClassifier()\n",
    "\n",
    "## Train the untuned model\n",
    "untuned_model.fit(X_train_pca, y_train_encoded)\n",
    "\n",
    "# Check the model's accuracy on the test set\n",
    "untuned_y_test_pred = untuned_model.predict(X_test_pca)\n",
    "print(accuracy_score(y_test_encoded, untuned_y_test_pred))\n",
    "print(precision_score(y_test_encoded, untuned_y_test_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KNN classfier to loop through different k values to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 40, 2):\n",
    "    loop_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    loop_model.fit(X_train, y_train_encoded)\n",
    "    train_score = loop_model.score(X_train, y_train_encoded)\n",
    "    test_score = loop_model.score(X_test, y_test_encoded)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "# Plot the results\n",
    "plt.plot(range(1, 40, 2), train_scores, marker='o', label=\"training scores\")\n",
    "plt.plot(range(1, 40, 2), test_scores, marker=\"x\", label=\"testing scores\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"accuracy score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best k, and refit the KNN classifier by using that k value.\n",
    "# Note that k=23 provides the best accuracy where the classifier is not overfitting.\n",
    "loop_model = KNeighborsClassifier(n_neighbors=23)\n",
    "loop_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Check the model's accuracy on the test set\n",
    "loop_y_test_pred = loop_model.predict(X_test)\n",
    "print(accuracy_score(y_test_encoded, loop_y_test_pred))\n",
    "print(precision_score(y_test_encoded, loop_y_test_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' The grid search below used to hyperparameter tune the KNN Classifier provided a k value = 1, with an accurancy score of .578. \n",
    "The code has been commented out code because it took 24min to run.'''\n",
    "# # Create a grid search KNN classifier\n",
    "# grid_model = KNeighborsClassifier()\n",
    "\n",
    "# # Define the parameter grid tuned KNN classifier\n",
    "# param_grid = {'n_neighbors': list(range(1, 25, 2)),\n",
    "#             'weights': ['uniform', 'distance'],\n",
    "#             'leaf_size': [10, 50, 100, 500]\n",
    "# }\n",
    "\n",
    "# # Create a GridSearchCV model\n",
    "# grid = GridSearchCV(grid_model, param_grid, verbose=3)\n",
    "\n",
    "# # Fit the model by using the grid search estimator.\n",
    "# # This will take the KNN model and try each combination of parameters.\n",
    "# grid.fit(X_train, y_train_encoded)\n",
    "\n",
    "# # Best parameter and score\n",
    "# print(f\"Best k: {grid.best_params_['n_neighbors']}\")\n",
    "# print(f\"Best cross-validated accuracy: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Odele's Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peta-Gaye's LR modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a logistic regression model.\n",
    "logistic_regression_model = LogisticRegression(max_iter=500, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and save the logistic regression model using the training data\n",
    "df_combined_lr_model = logistic_regression_model.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from the logistic regression model using the test data\n",
    "lr_predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Review the predictions\n",
    "lr_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the accuracy score for the test dataset.\n",
    "accuracy_score(y_test_encoded, lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the precision score for the test dataset.\n",
    "precision_score(y_test_encoded, lr_predictions, average='weighted', zero_division=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End Peta-Gaye's LR modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peta's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vadim's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Declare a Random Forest Classifier model\n",
    "random_forest_model = RandomForestClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and save the Random Forest Classifier model using the training data\n",
    "random_forest_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Generate predictions from the model using the test data\n",
    "RFM_pred = random_forest_model.predict(X_test)\n",
    "\n",
    "# Review the predictions\n",
    "RFM_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the accuracy score for the test dataset\n",
    "accuracy_score(y_test_encoded, RFM_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the precision score for the test dataset.\n",
    "precision_score(y_test_encoded, RFM_pred, average='weighted', zero_division=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "ai_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
