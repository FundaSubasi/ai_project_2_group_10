{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Data explanation placeholder\n",
    "\n",
    "(Talk about original two notebooks?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data\n",
    "df_movies = pd.read_csv(\"./Resources/movies_data.csv\")\n",
    "df_economics = pd.read_csv(\"./Resources/economics_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Economics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a 'Date' for a datetime index\n",
    "df_movies['Date'] = pd.to_datetime({\n",
    "    'year': df_movies['released_year'],\n",
    "    'month': df_movies['released_month'],\n",
    "    'day': df_movies['released_day']\n",
    "})\n",
    "\n",
    "# Setting `Date` as index\n",
    "df_movies.set_index('Date', inplace=True)\n",
    "\n",
    "# Ensuring index is sorted with ascending dates\n",
    "df_movies.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a `Year` and `Month` for concatenation\n",
    "df_economics['Year'] = df_economics['Date'].str.slice(0,4).astype(int)\n",
    "df_economics['Month'] = df_economics['Date'].str.slice(5,7).astype(int)\n",
    "\n",
    "# Renaming to `Year` and `Month` for concatenation\n",
    "df_movies.rename(columns={\n",
    "'released_year': 'Year',\n",
    "'released_month': 'Month'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ecomonic records: 507\n",
      "Total movie records: 15363\n"
     ]
    }
   ],
   "source": [
    "# Confirming total records before concatenation\n",
    "print(f'Total ecomonic records: {df_economics.shape[0]}')\n",
    "print(f'Total movie records: {df_movies.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 12188\n"
     ]
    }
   ],
   "source": [
    "# Combining datasets through concatenation\n",
    "df_combined = pd.merge(df_economics, df_movies, how='left', on=['Year', 'Month'])\n",
    "\n",
    "# Confirming total records after concatenation\n",
    "print(f'Total records: {df_combined.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the eventual `Target` for modelling\n",
    "df_combined['Target'] = df_combined['critical_success'] + ' ' +\\\n",
    "                        df_combined['financial_success'] + ' ' +\\\n",
    "                        df_combined['Economic Climate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "panned failure Lean to Bad                                    2200\n",
       "well liked failure Lean to Bad                                1897\n",
       "well liked failure Comfortable to Good                        1316\n",
       "panned failure Comfortable to Good                            1195\n",
       "alright failure Lean to Bad                                   1050\n",
       "alright failure Comfortable to Good                            753\n",
       "well liked excellent returns Lean to Bad                       709\n",
       "well liked excellent returns Comfortable to Good               527\n",
       "critical success failure Lean to Bad                           477\n",
       "well liked extraordinary returns Lean to Bad                   292\n",
       "critical success failure Comfortable to Good                   251\n",
       "well liked modest returns Lean to Bad                          221\n",
       "well liked extraordinary returns Comfortable to Good           201\n",
       "well liked moderate returns Lean to Bad                        193\n",
       "well liked modest returns Comfortable to Good                  164\n",
       "well liked moderate returns Comfortable to Good                139\n",
       "critical success excellent returns Lean to Bad                  76\n",
       "critical success excellent returns Comfortable to Good          65\n",
       "critical success extraordinary returns Lean to Bad              56\n",
       "critical success extraordinary returns Comfortable to Good      52\n",
       "panned broke even Lean to Bad                                   35\n",
       "alright excellent returns Lean to Bad                           28\n",
       "critical success modest returns Comfortable to Good             26\n",
       "alright excellent returns Comfortable to Good                   22\n",
       "critical success broke even Lean to Bad                         17\n",
       "critical success moderate returns Lean to Bad                   17\n",
       "alright moderate returns Lean to Bad                            16\n",
       "critical success moderate returns Comfortable to Good           16\n",
       "critical success broke even Comfortable to Good                 14\n",
       "critical success modest returns Lean to Bad                     14\n",
       "panned extraordinary returns Lean to Bad                        12\n",
       "panned broke even Comfortable to Good                           12\n",
       "panned excellent returns Lean to Bad                            12\n",
       "well liked broke even Lean to Bad                               11\n",
       "alright extraordinary returns Lean to Bad                       11\n",
       "panned moderate returns Lean to Bad                             10\n",
       "alright modest returns Comfortable to Good                      10\n",
       "panned modest returns Lean to Bad                                9\n",
       "well liked broke even Comfortable to Good                        9\n",
       "alright modest returns Lean to Bad                               9\n",
       "alright extraordinary returns Comfortable to Good                9\n",
       "panned excellent returns Comfortable to Good                     8\n",
       "alright moderate returns Comfortable to Good                     7\n",
       "panned moderate returns Comfortable to Good                      7\n",
       "panned modest returns Comfortable to Good                        6\n",
       "alright broke even Lean to Bad                                   3\n",
       "alright broke even Comfortable to Good                           2\n",
       "panned extraordinary returns Comfortable to Good                 2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of features to drop\n",
    "cols_to_drop = [\n",
    "    'Economic Climate',\n",
    "    'Year',\n",
    "    'Month',\n",
    "    'id',\n",
    "    'critical_success',\n",
    "    'financial_success',\n",
    "    'released_day'\n",
    "]\n",
    "\n",
    "# Dropping unneeded features\n",
    "df_combined.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                                              object\n",
       "CCI Value                                        float64\n",
       "CCI Rolling Mean                                 float64\n",
       "CCI Rolling Percent Change                       float64\n",
       "CPI Value                                        float64\n",
       "CPI Rolling Mean                                 float64\n",
       "CPI Rolling Percent Change                       float64\n",
       "Unemployment Rate (%)                            float64\n",
       "Unemployment Rate (%) Rolling Mean               float64\n",
       "Unemployment Rate Rolling Percent Change         float64\n",
       "CCI Rolling Percent Change Flag                   object\n",
       "CPI Rolling Percent Change Flag                   object\n",
       "Unemployment Rate Rolling Percent Change Flag     object\n",
       "title                                             object\n",
       "vote_average                                     float64\n",
       "vote_count                                       float64\n",
       "status                                            object\n",
       "release_date                                      object\n",
       "revenue                                          float64\n",
       "runtime                                          float64\n",
       "budget                                           float64\n",
       "original_language                                 object\n",
       "original_title                                    object\n",
       "popularity                                       float64\n",
       "genres                                            object\n",
       "production_companies                              object\n",
       "production_countries                              object\n",
       "spoken_languages                                  object\n",
       "cast                                              object\n",
       "director                                          object\n",
       "writers                                           object\n",
       "producers                                         object\n",
       "roi                                              float64\n",
       "Target                                            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining columns to scale and encode\n",
    "col_to_scale = [\n",
    "    'CCI Value', 'CCI Rolling Mean', 'CCI Rolling Percent Change',\n",
    "    'CPI Value', 'CPI Rolling Mean', 'CPI Rolling Percent Change',\n",
    "    'Unemployment Rate (%)', 'Unemployment Rate (%) Rolling Mean',\n",
    "    'Unemployment Rate Rolling Percent Change','vote_average', 'vote_count',\n",
    "    'revenue','runtime','budget', 'popularity', 'roi'\n",
    "]\n",
    "\n",
    "col_to_encode = [\n",
    "    'Date','CCI Rolling Percent Change Flag', 'CPI Rolling Percent Change Flag',\n",
    "    'Unemployment Rate Rolling Percent Change Flag', 'title',\n",
    "    'status', 'release_date','original_language', 'original_title',\n",
    "    'genres', 'production_companies', 'production_countries',\n",
    "    'spoken_languages', 'cast', 'director', 'writers', 'producers'\n",
    "]\n",
    "\n",
    "# Setup X and y variables\n",
    "X = df_combined.drop(columns='Target')\n",
    "y = df_combined['Target']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling and Econding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit(X_train[col_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train[col_to_scale])\n",
    "X_test_scaled = scaler.transform(X_test[col_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(drop='first', sparse=False, handle_unknown='ignore')\n",
    "encoder.fit(X_train[col_to_encode], y_train)\n",
    "\n",
    "# Transform each column into numpy arrays\n",
    "X_train_encoded = encoder.transform(X_train[col_to_encode]).values.reshape(-1, 1)\n",
    "X_test_encoded = encoder.transform(X_test[col_to_encode]).values.reshape(-1, 1)\n",
    "y_train_encoded = encoder.transform(y_train).values.reshape(-1, 1)\n",
    "y_test_encoded = encoder.transform(y_test).values.reshape(-1, 1)\n",
    "\n",
    "# Reorganize the numpy arrays into a DataFrame\n",
    "X_train_encoded = pd.DataFrame(X_train_encoded, columns=encoder.get_feature_names())\n",
    "X_test_encoded = pd.DataFrame(X_test_encoded, columns=encoder.get_feature_names())\n",
    "\n",
    "# Concatenate the encoded columns with the scaled columns\n",
    "X_train = pd.concat([X_train_scaled, X_train_encoded], axis=1)\n",
    "X_test = pd.concat([X_test_scaled, X_test_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Playtime!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eric's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funda's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalvin's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Odele's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peta's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vadim's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
